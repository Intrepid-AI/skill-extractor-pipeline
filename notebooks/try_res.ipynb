{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EAG7CG7c2Aoq",
        "outputId": "05b561cb-b805-415a-e2dc-8d98be8d4f9b"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to\n",
            "[nltk_data]     C:\\Users\\Z004ET6Z\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to\n",
            "[nltk_data]     C:\\Users\\Z004ET6Z\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "import re\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "#To do: preload function for downloading and loading \n",
        "nltk.download([\"stopwords\",\"wordnet\"])\n",
        "\n",
        "def cleaning_text(text):\n",
        "  review = re.sub(\n",
        "        '(@[A-Za-z0-9]+)|([^0-9A-Za-z \\t])|(\\w+:\\/\\/\\S+)|^rt|http.+?\"',\n",
        "        \" \",\n",
        "        text,)\n",
        "  review = review.lower()\n",
        "  review = review.split()\n",
        "  lm = WordNetLemmatizer()\n",
        "  review = [\n",
        "      lm.lemmatize(word)\n",
        "      for word in review\n",
        "      if not word in set(stopwords.words(\"english\"))\n",
        "  ]\n",
        "  review = \" \".join(review)\n",
        "  review = review.lower()\n",
        "  cleaned_text = review \n",
        "  return cleaned_text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 522
        },
        "id": "bKo627LR2yQ-",
        "outputId": "4833171c-5254-4766-b4ae-c43823dd84f5"
      },
      "outputs": [],
      "source": [
        "#!pip install pdfplumber"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "oCnPE2qD2nuF"
      },
      "outputs": [],
      "source": [
        "import pdfplumber"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "zgMN5WzM2xLN"
      },
      "outputs": [],
      "source": [
        "def pdf_to_text(pdf_path):\n",
        "  with pdfplumber.open(pdf_path) as pdf:\n",
        "      extracted_text = []\n",
        "      for page in pdf.pages:\n",
        "          text = page.extract_text()\n",
        "          extracted_text.append(text)\n",
        "      extracted_text = \" \".join(extracted_text)\n",
        "      return extracted_text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "jxcYZ7nm28_w"
      },
      "outputs": [],
      "source": [
        "def get_skills(text,nlp):\n",
        "    doc = nlp(text)\n",
        "    myset = []\n",
        "    subset = []\n",
        "    for ent in doc.ents:\n",
        "        if ent.label_ == \"SKILL\":\n",
        "            subset.append(ent.text)\n",
        "    myset.append(subset)\n",
        "    return subset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "a_Z3szN-3F1l"
      },
      "outputs": [],
      "source": [
        "def unique_skills(x):\n",
        "    return list(set(x))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "sG3paNZ83L6p"
      },
      "outputs": [],
      "source": [
        "import spacy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n28OttdT34yq",
        "outputId": "590e47a9-0087-4189-a6b8-6e6105214935"
      },
      "outputs": [],
      "source": [
        "#!python -m spacy download en_core_web_lg"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "p08D8MGE3ZVa"
      },
      "outputs": [],
      "source": [
        "nlp = spacy.load(\"en_core_web_lg\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "tcW6CO6I3fpq"
      },
      "outputs": [],
      "source": [
        "skill_pattern_path = r\"C:\\Users\\Z004ET6Z\\OneDrive - Siemens AG\\Desktop\\interai\\skill_extractor\\skills_annotations\\jz_skill_patterns.jsonl\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "qua8knMY4O_K"
      },
      "outputs": [],
      "source": [
        "ruler = nlp.add_pipe(\"entity_ruler\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qmUxcF1I4SCS",
        "outputId": "0829ff3a-21d9-4521-fbf7-c9d26fc10f75"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<spacy.pipeline.entityruler.EntityRuler at 0x2239a2399c0>"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ruler.from_disk(skill_pattern_path)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "oEeTySdr4bH8"
      },
      "outputs": [],
      "source": [
        "def skill_extractor(pdf_path):\n",
        "  extracted_text = pdf_to_text(pdf_path)\n",
        "  cleaned_text = cleaning_text(extracted_text)\n",
        "  skills = get_skills(cleaned_text,nlp)\n",
        "  uniq_skills = unique_skills(skills)\n",
        "  extracted_skills = {\"SKILLS\":uniq_skills}\n",
        "  return extracted_skills\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HTOlXb3U4nYx"
      },
      "source": [
        "# Rough"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [],
      "source": [
        "res_path = r\"C:\\Users\\Z004ET6Z\\OneDrive - Siemens AG\\Desktop\\interai\\skill_extractor\\artifacts\\jc.pdf\"\n",
        "jd_path = r\"C:\\Users\\Z004ET6Z\\OneDrive - Siemens AG\\Desktop\\interai\\skill_extractor\\artifacts\\Lead Data Scientist.docx\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "W5676BNz6wVq"
      },
      "outputs": [],
      "source": [
        "extr = pdf_to_text(r\"C:\\Users\\Z004ET6Z\\OneDrive - Siemens AG\\Desktop\\interai\\skill_extractor\\artifacts\\jc.pdf\")\n",
        "cltx = cleaning_text(extr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "WfXdXeSC4krA"
      },
      "outputs": [],
      "source": [
        "a = skill_extractor(res_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "svYR13Vs4v0z",
        "outputId": "faeb2ba1-023a-41a6-acb4-eca0967e8719"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'SKILLS': ['artificial intelligence',\n",
              "  'opencv',\n",
              "  'github',\n",
              "  'encryption',\n",
              "  'analytics',\n",
              "  'anomaly detection',\n",
              "  'machine learning',\n",
              "  'framework',\n",
              "  'flask',\n",
              "  'network model',\n",
              "  'software',\n",
              "  'time series',\n",
              "  'data science',\n",
              "  'inference',\n",
              "  'plotly',\n",
              "  'object detection',\n",
              "  'support',\n",
              "  'petroleum engineering',\n",
              "  'database',\n",
              "  'deep learning',\n",
              "  'pytorch',\n",
              "  'python',\n",
              "  'numpy',\n",
              "  'rabbitmq',\n",
              "  'tensorflow',\n",
              "  'random forest',\n",
              "  'algorithm',\n",
              "  'engineering',\n",
              "  'simulation',\n",
              "  'ai',\n",
              "  'computer vision']}"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "a"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 470
        },
        "id": "yPDu22ms43fs",
        "outputId": "e35854ab-573d-4fc9-b9ca-b87bfe45c392"
      },
      "outputs": [],
      "source": [
        "# !pip install gensim==3.8"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ld-QC0FU6jEq",
        "outputId": "b5f3d125-5760-4825-bec0-423bdff9445b"
      },
      "outputs": [],
      "source": [
        "# !pip install docx2txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "H5UOaqbL5LZE"
      },
      "outputs": [],
      "source": [
        "import docx2txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "MenkrnQr7B1Z"
      },
      "outputs": [],
      "source": [
        "resume = docx2txt.process(jd_path)\n",
        "text_resume = str(resume)\n",
        "cltx_jd = cleaning_text(text_resume)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 140
        },
        "id": "RUyF6sJm7Hmu",
        "outputId": "c824c9e6-c46a-4cb4-c085-e6b212ea8b45"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'lead data scientist job summary product first strategy building new age solution healthcare industry thatoperate intersection business math technology drive profitable growth client specifically building b2b saas product powered ai ml algorithm tomine data broad deep lead data scientist leadership role collaborate product manager customer success manager driving roadmap data science team deliver new age solution get data science strategy initiative support product roadmap promote culture creative thinking solve age old complex business problem leverage traditional statistical mathematical modelling new age ai ml technique convert black box ai model explainable model using xai roll sleeve work group smart engineer data scientist todeliver promise hiring guiding coaching data science team scale keep pace withfast growth contributing thought leadership whitepapers article conference need make impact graduate iit bombay delhi varanasi kanpur kharagpur madras roorkee passing year 2017 2018 2019 2020 experience product analyst preferably u healthcare insurance believer democratizing advanced analytics empower business user tosolve complex business problem doer get thing done inspire team master degree machine learning mathematics computer science statistic economics related field 3 year hand experience developing applying data driven solution ina corporate consulting setting preferably healthcare industry familiarity regression boosting segmentation mmm deep learning ability solve data science problem using traditional advanced analytical ai ml dl technique experience azure mlops r python spark tensorflow caffe pytorch big data platform like apache spark hadoop strong experience knowledge data engineering data modelling algorithm data science intellectual curiosity excellent problem solving skill including ability structure prioritize approach maximum impact get young millennial team work chance work product based company exciting recognition plan complete wfh 3 paid trip per year health insurance etc open leave policy flexible working hour'"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "cltx_jd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OqLO7ZoF7cIb",
        "outputId": "fbc84faf-5945-4827-c62e-33651b267a94"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "str"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "type(cltx_jd)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "ikPfkMMZ4xQA"
      },
      "outputs": [],
      "source": [
        "from gensim.summarization.summarizer import summarize\n",
        "from gensim.summarization import keywords"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 140
        },
        "id": "ay6Cj90p42Dg",
        "outputId": "b4ddbd8c-af17-439f-d55a-4a4692ceb3a7"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'jaiyesh chahar mob 919696900002 jaiyesh0002 com github youtube channel professional summary innovative result orientated data scientist strong mathematics statistic background 2 year experience ai machine learning statistical modelling time series analysis deep learning computer vision python also community mentor python data science oil gas industry experience working client different industry like oil gas energy automotive manufacturing smart city automation education master technology petroleum engineering minor machine learning iit indian school mine dhanbad 2019 2021 bachelor technology petroleum engineering university petroleum energy study dehradun 2015 2019 experience siemens data scientist oct 2021 present automotive part anomaly detection developed object detection pipeline damage detection hole counting developed mlops pipeline model version handling developing end end software pipeline final product deep learning framework multiple use case production involving multiple service leveraging rabbitmq skillsets computer vision object detection rabbitmq mlops pytorch tensorflow future mega smart city automation developed solution multiple use case confidential next generation environment compliance assurance construction location smart city using drone image developed inference pipeline service computer vision use case using object detection image classification method implemented tiny object detection image classification skillsets computer vision object detection rabbitmq docker pytorch tensorflow opencv dielectric fluid leakage detection developed data driven solution detection leakage dielectric fluid high pressure fluid filled pipe underground electricity transmission line developed sequential neural network leak prediction using historical data developed streamlit app performing analysis sensor data skillsets time series analysis lstm long short term memory ann random forest streamlit electric vehicle smart battery solution contributed development electric vehicle smart battery solution various application forecasting useful life ev battery remaining range energy demand charging station using data driven approach skillsets time series analysis lstm long short term memory flask regression automotive defect analysis developed deep learning inference pipeline detection defective part automotive part dicelytics pvt ltd dice technology llc reservoir engineer data scientist jan 2021 sept 2021 physic assisted machine learning tool oil gas industry developed reservoir physic assisted artificial intelligence machine learning reinforced model simulate analyze support field implementation reservoir recovery management technology developed machine learning based classification technique using global database enhanced oil recovery screening selecting best possible enhanced oil recovery candidate given reservoir crude property developed tool history matching hydrocarbon production forecasting using sequential deep learning architecture skillsets time series analysis machine learning lstm physic indian institute technology indian school mine dhanbad teaching assistant july 2019 may 2021 helped professor organizing lecture content setting quiz exam paper evaluating answer sheet invigilation research work patent filed data encryption time series data published research work data driven approach hydrocarbon production forecasting using machine learning technique journal petroleum science engineering doi pre print teeth cavity classification classifying carious lesion based g v black caries classification using multiple hierarchical classification model generative adversarial network model sensor data generation based remaining useful life classification industrial equipment skill machine learning deep learning statistic linear algebra intuitive applied ml algorithm time series analysis computer vision predictive maintenance predictive analysis mlops framework kera tensorflow pytorch scikit learn opencv streamlit docker rabbitmq numpy panda matplotlib plotly flask domain skill engineering mathematics univariate multi variate calculus numerical simulation oil gas physic achievement open source contribution 1 gate 2020 pe air 64 02 2020 graduate aptitude test engineer 2 delivered multiple workshop many university across globe application python machine learning oil gas industry 3 delivered multiple workshop platform like analytics vidhya ai planet multiple topic data science 4 developing online tutorial youtube data science statistic physic based engineer 5 predictive maintenance pump failure prediction using machine learning 6 prediction hydrocarbon production based production parameter volve field data using machine learning 7 reservoir heterogeneity model statistical approach applying statistic describe reservoir rock heterogeneity extracurriculars co founder petroleum scratch e learning venture community mentor python data science petroleum data science contributor society petroleum engineer international wikipedia petrowiki public speaker presented talked several webinars workshop actively maintain github repository sharing project learning community taught physic ngo'"
            ]
          },
          "execution_count": 34,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "cltx"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vyQO3tXF69WA",
        "outputId": "a0f43e07-f49e-4052-803f-28b28cd974da"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "With a Product First strategy, we are building New Age solutions for the healthcare industry thatoperate at the intersection of business, math, and technology to drive profitable growth for our clients.\n",
            "The Lead Data Scientist is a leadership role that will collaborate with Product Managers and Customer Success Managers in driving the roadmap for the data science team to deliver the New Age solutions.\n",
            "Own the data science strategy and initiatives to support the product roadmap.\n",
            "3+ years of hands-on experience developing and applying data-driven solutions ina corporate or consulting setting, preferably in a Healthcare industry.\n",
            "Ability to solve data science problems using both traditional and advanced analytical (AI/ML/DL) techniques.\n"
          ]
        }
      ],
      "source": [
        "print(summarize(text_resume, ratio=0.2))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GP3pwYoj7ZM9",
        "outputId": "b4a04847-e0d7-4041-fb4a-888a5c6835d6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "experience in AI, Machine Learning, Statistical Modelling, Time Series Analysis, Deep Learning, Computer Vision, Python.\n",
            "a community mentor for Python and Data Science in the Oil and Gas Industry.\n",
            "different industries like Oil and gas, Energy, Automotive, Manufacturing and Smart City Automation.\n",
            "• Master of Technology: Petroleum Engineering minor in Machine Learning, IIT (Indian School of Mines) – Dhanbad\n",
            "o Developing end to end software pipeline (final product) for deep learning frameworks of multiple use cases in\n",
            "o Developed inference pipeline services of computer vision use cases using object detection and image classification\n",
            "o Developed a data driven solution for detection of leakage of dielectric fluid in high pressure fluid–filled pipe of\n",
            "o Contributed to development of an Electric Vehicle smart battery solution having various applications that are\n",
            "o Developed a deep learning inference pipeline for detection of defective part in automotive part.\n",
            "• Physics assisted machine learning tools for Oil and Gas Industry\n",
            "o Developed a reservoir physics assisted artificial intelligence and machine learning reinforced model to simulate,\n",
            "o Developed Machine Learning Based Classification technique using Global Database for Enhanced Oil Recovery\n",
            "Skillsets: Time Series analysis, Machine Learning, LSTM, Physics\n",
            "• Published Research Work: Data-driven approach for hydrocarbon production forecasting using machine learning\n",
            "2. Delivered multiple workshops in many Universities across the globe on Applications of Python and Machine Learning in Oil\n",
            "4. Developing online tutorials on Youtube for Data Science, Statistics for physics based engineers.\n",
            "6. Prediction of Hydrocarbon Production based on Production Parameters for Volve field data using Machine Learning.\n"
          ]
        }
      ],
      "source": [
        "print(summarize(extr, ratio=0.2))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "id": "oxGAM8fO7v91",
        "outputId": "2b7a9fef-3161-4ae9-9414-1c0a856a6968"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'With a Product First strategy, we are building New Age solutions for the healthcare industry thatoperate at the intersection of business, math, and technology to drive profitable growth for our clients.\\nThe Lead Data Scientist is a leadership role that will collaborate with Product Managers and Customer Success Managers in driving the roadmap for the data science team to deliver the New Age solutions.\\nOwn the data science strategy and initiatives to support the product roadmap.\\n3+ years of hands-on experience developing and applying data-driven solutions ina corporate or consulting setting, preferably in a Healthcare industry.\\nAbility to solve data science problems using both traditional and advanced analytical (AI/ML/DL) techniques.'"
            ]
          },
          "execution_count": 44,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "summarize(text_resume, ratio=0.2)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q1UjfKDIGD6b"
      },
      "source": [
        "### Method 1: CountVectorizer on complete text and then Similiarity"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "7Jubx2Cl72hP"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "-eKvekyCCj5l"
      },
      "outputs": [],
      "source": [
        "Match_Test=[cltx,cltx_jd]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "agSxyTuL8GLk"
      },
      "outputs": [],
      "source": [
        "cv=CountVectorizer()\n",
        "count_matrix=cv.fit_transform(Match_Test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D8FHE5Sv91sY",
        "outputId": "280dbc75-e8f3-416c-fa3d-8654598516ea"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Similarity is : [[1.         0.38446105]\n",
            " [0.38446105 1.        ]]\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "print('Similarity is :',cosine_similarity(count_matrix))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uIcMAxmODKon",
        "outputId": "4abd2f3a-f323-4ce5-e8ea-f17b4d301487"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Match Percentage is :38.45% to Requirement\n"
          ]
        }
      ],
      "source": [
        "MatchPercentage=cosine_similarity(count_matrix)[0][1]*100\n",
        "MatchPercentage=round(MatchPercentage,2)\n",
        "print('Match Percentage is :'+ str(MatchPercentage)+'% to Requirement')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 140
        },
        "id": "LUUxZJUYDOsE",
        "outputId": "1e059639-9e8f-4664-a73f-0d83887dae37"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'jaiyesh chahar mob 919696900002 jaiyesh0002 com github youtube channel professional summary innovative result orientated data scientist strong mathematics statistic background 2 year experience ai machine learning statistical modelling time series analysis deep learning computer vision python also community mentor python data science oil gas industry experience working client different industry like oil gas energy automotive manufacturing smart city automation education master technology petroleum engineering minor machine learning iit indian school mine dhanbad 2019 2021 bachelor technology petroleum engineering university petroleum energy study dehradun 2015 2019 experience siemens data scientist oct 2021 present automotive part anomaly detection developed object detection pipeline damage detection hole counting developed mlops pipeline model version handling developing end end software pipeline final product deep learning framework multiple use case production involving multiple service leveraging rabbitmq skillsets computer vision object detection rabbitmq mlops pytorch tensorflow future mega smart city automation developed solution multiple use case confidential next generation environment compliance assurance construction location smart city using drone image developed inference pipeline service computer vision use case using object detection image classification method implemented tiny object detection image classification skillsets computer vision object detection rabbitmq docker pytorch tensorflow opencv dielectric fluid leakage detection developed data driven solution detection leakage dielectric fluid high pressure fluid filled pipe underground electricity transmission line developed sequential neural network leak prediction using historical data developed streamlit app performing analysis sensor data skillsets time series analysis lstm long short term memory ann random forest streamlit electric vehicle smart battery solution contributed development electric vehicle smart battery solution various application forecasting useful life ev battery remaining range energy demand charging station using data driven approach skillsets time series analysis lstm long short term memory flask regression automotive defect analysis developed deep learning inference pipeline detection defective part automotive part dicelytics pvt ltd dice technology llc reservoir engineer data scientist jan 2021 sept 2021 physic assisted machine learning tool oil gas industry developed reservoir physic assisted artificial intelligence machine learning reinforced model simulate analyze support field implementation reservoir recovery management technology developed machine learning based classification technique using global database enhanced oil recovery screening selecting best possible enhanced oil recovery candidate given reservoir crude property developed tool history matching hydrocarbon production forecasting using sequential deep learning architecture skillsets time series analysis machine learning lstm physic indian institute technology indian school mine dhanbad teaching assistant july 2019 may 2021 helped professor organizing lecture content setting quiz exam paper evaluating answer sheet invigilation research work patent filed data encryption time series data published research work data driven approach hydrocarbon production forecasting using machine learning technique journal petroleum science engineering doi pre print teeth cavity classification classifying carious lesion based g v black caries classification using multiple hierarchical classification model generative adversarial network model sensor data generation based remaining useful life classification industrial equipment skill machine learning deep learning statistic linear algebra intuitive applied ml algorithm time series analysis computer vision predictive maintenance predictive analysis mlops framework kera tensorflow pytorch scikit learn opencv streamlit docker rabbitmq numpy panda matplotlib plotly flask domain skill engineering mathematics univariate multi variate calculus numerical simulation oil gas physic achievement open source contribution 1 gate 2020 pe air 64 02 2020 graduate aptitude test engineer 2 delivered multiple workshop many university across globe application python machine learning oil gas industry 3 delivered multiple workshop platform like analytics vidhya ai planet multiple topic data science 4 developing online tutorial youtube data science statistic physic based engineer 5 predictive maintenance pump failure prediction using machine learning 6 prediction hydrocarbon production based production parameter volve field data using machine learning 7 reservoir heterogeneity model statistical approach applying statistic describe reservoir rock heterogeneity extracurriculars co founder petroleum scratch e learning venture community mentor python data science petroleum data science contributor society petroleum engineer international wikipedia petrowiki public speaker presented talked several webinars workshop actively maintain github repository sharing project learning community taught physic ngo'"
            ]
          },
          "execution_count": 34,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "cltx"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 140
        },
        "id": "PCPLJgtBDa9B",
        "outputId": "ef1c7e24-2f2d-48ef-df75-c005178f61d8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'lead data scientist job summary product first strategy building new age solution healthcare industry thatoperate intersection business math technology drive profitable growth client specifically building b2b saas product powered ai ml algorithm tomine data broad deep lead data scientist leadership role collaborate product manager customer success manager driving roadmap data science team deliver new age solution get data science strategy initiative support product roadmap promote culture creative thinking solve age old complex business problem leverage traditional statistical mathematical modelling new age ai ml technique convert black box ai model explainable model using xai roll sleeve work group smart engineer data scientist todeliver promise hiring guiding coaching data science team scale keep pace withfast growth contributing thought leadership whitepapers article conference need make impact graduate iit bombay delhi varanasi kanpur kharagpur madras roorkee passing year 2017 2018 2019 2020 experience product analyst preferably u healthcare insurance believer democratizing advanced analytics empower business user tosolve complex business problem doer get thing done inspire team master degree machine learning mathematics computer science statistic economics related field 3 year hand experience developing applying data driven solution ina corporate consulting setting preferably healthcare industry familiarity regression boosting segmentation mmm deep learning ability solve data science problem using traditional advanced analytical ai ml dl technique experience azure mlops r python spark tensorflow caffe pytorch big data platform like apache spark hadoop strong experience knowledge data engineering data modelling algorithm data science intellectual curiosity excellent problem solving skill including ability structure prioritize approach maximum impact get young millennial team work chance work product based company exciting recognition plan complete wfh 3 paid trip per year health insurance etc open leave policy flexible working hour'"
            ]
          },
          "execution_count": 35,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "cltx_jd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "_Xyb7__7Ddcb"
      },
      "outputs": [],
      "source": [
        "skills_resume = get_skills(cltx,nlp)\n",
        "uniq_skills_resume = unique_skills(skills_resume)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "A4NnoWzQDziq"
      },
      "outputs": [],
      "source": [
        "skills_jd = get_skills(cltx_jd,nlp)\n",
        "uniq_skills_jd = unique_skills(skills_jd)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "37cHFzkKD9Mu",
        "outputId": "3af89f8b-0b67-4361-c2cb-431ddfbb3109"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['artificial intelligence',\n",
              " 'opencv',\n",
              " 'github',\n",
              " 'encryption',\n",
              " 'analytics',\n",
              " 'anomaly detection',\n",
              " 'machine learning',\n",
              " 'framework',\n",
              " 'flask',\n",
              " 'network model',\n",
              " 'software',\n",
              " 'time series',\n",
              " 'data science',\n",
              " 'inference',\n",
              " 'plotly',\n",
              " 'object detection',\n",
              " 'support',\n",
              " 'petroleum engineering',\n",
              " 'database',\n",
              " 'deep learning',\n",
              " 'pytorch',\n",
              " 'python',\n",
              " 'numpy',\n",
              " 'rabbitmq',\n",
              " 'tensorflow',\n",
              " 'random forest',\n",
              " 'algorithm',\n",
              " 'engineering',\n",
              " 'simulation',\n",
              " 'ai',\n",
              " 'computer vision']"
            ]
          },
          "execution_count": 38,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "uniq_skills_resume"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8tF8ZmfmD-wY",
        "outputId": "95837595-3945-49eb-b6ae-935dc250b8a4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['analytics',\n",
              " 'segmentation',\n",
              " 'machine learning',\n",
              " 'box',\n",
              " 'computer science',\n",
              " 'ml',\n",
              " 'data science',\n",
              " 'azure',\n",
              " 'support',\n",
              " 'deep learning',\n",
              " 'hadoop',\n",
              " 'pytorch',\n",
              " 'python',\n",
              " 'business',\n",
              " 'big data',\n",
              " 'tensorflow',\n",
              " 'algorithm',\n",
              " 'apache spark',\n",
              " 'engineering',\n",
              " 'ai']"
            ]
          },
          "execution_count": 39,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "uniq_skills_jd"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W9HYDl_tGQH-"
      },
      "source": [
        "### Method 2: Word2vec of EXTRACTED SKILLS from jd and **resume** and then Similiarity"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "id": "f3kdGaBfFNUT"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from gensim.models import Word2Vec\n",
        "from sklearn.metrics.pairwise import cosine_similarity"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g_zFaD8RFJaT",
        "outputId": "978e44a3-1993-44a6-d449-dd7ba41a1df9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cosine Similarity: 0.4286661\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "# Train Word2Vec model on a corpus of skills\n",
        "corpus = [uniq_skills_jd,uniq_skills_resume] # Combine both lists into a corpus\n",
        "model = Word2Vec(corpus, min_count=1)  # Train the Word2Vec model\n",
        "\n",
        "# Calculate average vector representations for each list of skills\n",
        "vector1 = np.mean([model.wv[skill] for skill in uniq_skills_jd if skill in model.wv], axis=0)\n",
        "vector2 = np.mean([model.wv[skill] for skill in uniq_skills_resume if skill in model.wv], axis=0)\n",
        "\n",
        "# Reshape the vectors if necessary\n",
        "vector1 = vector1.reshape(1, -1)  # Reshape to a row vector\n",
        "vector2 = vector2.reshape(1, -1)  # Reshape to a row vector\n",
        "\n",
        "# Calculate cosine similarity\n",
        "similarity_score = cosine_similarity(vector1, vector2)\n",
        "\n",
        "print(\"Cosine Similarity:\", similarity_score[0][0])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Op1oAeGHHvsC"
      },
      "source": [
        "### Method 3: Word2vec of EXTRACTED SKILLS from jd and **resume** and then Similiarity"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "Al_VHmLqH3_T"
      },
      "outputs": [],
      "source": [
        "complete_resume_skills = ' '.join(uniq_skills_resume)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "GKZmgFJrIRkv"
      },
      "outputs": [],
      "source": [
        "complete_jd_skills = ' '.join(uniq_skills_jd)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "ul4bq9eYEFQS"
      },
      "outputs": [],
      "source": [
        "Match_Test=[complete_resume_skills,complete_jd_skills]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "RJGA4j6HEFQS"
      },
      "outputs": [],
      "source": [
        "cv=CountVectorizer()\n",
        "count_matrix=cv.fit_transform(Match_Test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w0arhAtYEFQS",
        "outputId": "78b8fb6f-efa8-46f1-ff49-1c84d735b76b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Similarity is : [[1.         0.51031036]\n",
            " [0.51031036 1.        ]]\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "print('Similarity is :',cosine_similarity(count_matrix))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ji4bcbBoEFQS",
        "outputId": "d3345935-ffe5-44ea-c038-6b403846d01f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Match Percentage is :51.03% to Requirement\n"
          ]
        }
      ],
      "source": [
        "MatchPercentage=cosine_similarity(count_matrix)[0][1]*100\n",
        "MatchPercentage=round(MatchPercentage,2)\n",
        "print('Match Percentage is :'+ str(MatchPercentage)+'% to Requirement')"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### handling text files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "TiPAd1FyIeqm"
      },
      "outputs": [],
      "source": [
        "txt_path = r\"C:\\Users\\Z004ET6Z\\OneDrive - Siemens AG\\Desktop\\interai\\skill_extractor\\artifacts\\jd.txt\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {},
      "outputs": [],
      "source": [
        "with open(txt_path) as f:\n",
        "    contents = f.readlines()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['\\n',\n",
              " 'Ingersoll Rand is a global market leader with a broad range of innovative and mission-critical air, fluid, energy and medical technologies, providing services and solutions to increase industrial productivity and efficiency. Since merging with Gardner Denver in early 2020, we have more than 300 years of combined experience and innovative expertise.\\n',\n",
              " '\\n',\n",
              " 'JD - \\n',\n",
              " '\\n',\n",
              " '\\n',\n",
              " 'Principal Responsibilities\\n',\n",
              " '\\n',\n",
              " '·       Use of field data to assist in the creation of predictive and prescriptive asset fault signatures.\\n',\n",
              " '\\n',\n",
              " '·       Ability to understand working of compressors, failure modes, root causes and control systems \\n',\n",
              " '\\n',\n",
              " '·       In-depth knowledge of Statistics and Machine Learning concepts and should be able to apply them to business problems\\n',\n",
              " '\\n',\n",
              " '·       Ability to perform statistical modelling (predictive, regression, classification, hypotheses testing, multivariate analysis, Time Series, Clustering, forecasting, ARIMA) using Python.\\n',\n",
              " '\\n',\n",
              " '·       Write complex SQL queries to perform data extraction from various data sources.\\n',\n",
              " '\\n',\n",
              " '·       Lead development and implementation of \"state-of-the art\" analytics practices and technology to achieve excellence in field data analytics.\\n',\n",
              " '\\n',\n",
              " '·       Ability to create good visualization in salesforce/google cloud platform with using big query data.\\n',\n",
              " '\\n',\n",
              " '·       Ideal candidate should take full ownership for end-to-end deliverables starting from data collection, cleaning, model validation and bring into production environment and maintain it. Should have experience to maintain model on google cloud platform.\\n',\n",
              " '\\n',\n",
              " '·       Experience in predictive analytics of field installation is must.\\n',\n",
              " '\\n',\n",
              " '·       Identify and implement AI tools to utilize machine learning to provide insights on how to optimize asset operation to minimize cost and maximize reliability.\\n',\n",
              " '\\n',\n",
              " ' \\n',\n",
              " '\\n',\n",
              " ' \\n',\n",
              " '\\n',\n",
              " ' \\n',\n",
              " '\\n',\n",
              " 'Candidate Profile\\n',\n",
              " '\\n',\n",
              " '·       Master or Bachelor’s degree in Engineering or Artificial intelligence or computer science\\n',\n",
              " '\\n',\n",
              " '·       At least 3-5 years of demonstrated experience in data analytics for industrial or commercial product settings.\\n',\n",
              " '\\n',\n",
              " '·       Understanding of controls, compressor system are added advantage.\\n',\n",
              " '\\n',\n",
              " '·       Working knowledge of Python, and SQL languages\\n',\n",
              " '\\n',\n",
              " '·       Exposure to cloud based databases – Google cloud platform, data compliance, & integrating ‘big-data’ into initiative that drive business decision.\\n',\n",
              " '\\n',\n",
              " '·       Strong analytical background – must include ability to identify relevant data within the organization and analyze it creatively.']"
            ]
          },
          "execution_count": 51,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "contents"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {},
      "outputs": [],
      "source": [
        "complete_jd_txt = ' '.join(contents)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'\\n Ingersoll Rand is a global market leader with a broad range of innovative and mission-critical air, fluid, energy and medical technologies, providing services and solutions to increase industrial productivity and efficiency. Since merging with Gardner Denver in early 2020, we have more than 300 years of combined experience and innovative expertise.\\n \\n JD - \\n \\n \\n Principal Responsibilities\\n \\n ·       Use of field data to assist in the creation of predictive and prescriptive asset fault signatures.\\n \\n ·       Ability to understand working of compressors, failure modes, root causes and control systems \\n \\n ·       In-depth knowledge of Statistics and Machine Learning concepts and should be able to apply them to business problems\\n \\n ·       Ability to perform statistical modelling (predictive, regression, classification, hypotheses testing, multivariate analysis, Time Series, Clustering, forecasting, ARIMA) using Python.\\n \\n ·       Write complex SQL queries to perform data extraction from various data sources.\\n \\n ·       Lead development and implementation of \"state-of-the art\" analytics practices and technology to achieve excellence in field data analytics.\\n \\n ·       Ability to create good visualization in salesforce/google cloud platform with using big query data.\\n \\n ·       Ideal candidate should take full ownership for end-to-end deliverables starting from data collection, cleaning, model validation and bring into production environment and maintain it. Should have experience to maintain model on google cloud platform.\\n \\n ·       Experience in predictive analytics of field installation is must.\\n \\n ·       Identify and implement AI tools to utilize machine learning to provide insights on how to optimize asset operation to minimize cost and maximize reliability.\\n \\n  \\n \\n  \\n \\n  \\n \\n Candidate Profile\\n \\n ·       Master or Bachelor’s degree in Engineering or Artificial intelligence or computer science\\n \\n ·       At least 3-5 years of demonstrated experience in data analytics for industrial or commercial product settings.\\n \\n ·       Understanding of controls, compressor system are added advantage.\\n \\n ·       Working knowledge of Python, and SQL languages\\n \\n ·       Exposure to cloud based databases – Google cloud platform, data compliance, & integrating ‘big-data’ into initiative that drive business decision.\\n \\n ·       Strong analytical background – must include ability to identify relevant data within the organization and analyze it creatively.'"
            ]
          },
          "execution_count": 54,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "complete_jd_txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {},
      "outputs": [],
      "source": [
        "clean_jd_txt = cleaning_text(complete_jd_txt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'ingersoll rand global market leader broad range innovative mission critical air fluid energy medical technology providing service solution increase industrial productivity efficiency since merging gardner denver early 2020 300 year combined experience innovative expertise jd principal responsibility use field data assist creation predictive prescriptive asset fault signature ability understand working compressor failure mode root cause control system depth knowledge statistic machine learning concept able apply business problem ability perform statistical modelling predictive regression classification hypothesis testing multivariate analysis time series clustering forecasting arima using python write complex sql query perform data extraction various data source lead development implementation state art analytics practice technology achieve excellence field data analytics ability create good visualization salesforce google cloud platform using big query data ideal candidate take full ownership end end deliverable starting data collection cleaning model validation bring production environment maintain experience maintain model google cloud platform experience predictive analytics field installation must identify implement ai tool utilize machine learning provide insight optimize asset operation minimize cost maximize reliability candidate profile master bachelor degree engineering artificial intelligence computer science least 3 5 year demonstrated experience data analytics industrial commercial product setting understanding control compressor system added advantage working knowledge python sql language exposure cloud based database google cloud platform data compliance integrating big data initiative drive business decision strong analytical background must include ability identify relevant data within organization analyze creatively'"
            ]
          },
          "execution_count": 56,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "clean_jd_txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {},
      "outputs": [],
      "source": [
        "skills_jd_txt = get_skills(clean_jd_txt,nlp)\n",
        "uniq_skills_jd_txt = unique_skills(skills_jd_txt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['visualization',\n",
              " 'python',\n",
              " 'business',\n",
              " 'mode',\n",
              " 'data extraction',\n",
              " 'multivariate analysis',\n",
              " 'artificial intelligence',\n",
              " 'time series',\n",
              " 'big data',\n",
              " 'database',\n",
              " 'analytics',\n",
              " 'engineering',\n",
              " 'machine learning',\n",
              " 'testing',\n",
              " 'computer science',\n",
              " 'google',\n",
              " 'ai']"
            ]
          },
          "execution_count": 58,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "uniq_skills_jd_txt"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Both Pdf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {},
      "outputs": [],
      "source": [
        "jd = skill_extractor(r\"C:\\Users\\Z004ET6Z\\OneDrive - Siemens AG\\Desktop\\interai\\skill_extractor\\artifacts\\jd_sr.pdf\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'SKILLS': ['artificial intelligence',\n",
              "  'serverless',\n",
              "  'analytics',\n",
              "  'java',\n",
              "  'business intelligence',\n",
              "  'machine learning',\n",
              "  'box',\n",
              "  'presto',\n",
              "  'software',\n",
              "  'ml',\n",
              "  'time series',\n",
              "  'data science',\n",
              "  'throughput',\n",
              "  'design',\n",
              "  'oracle',\n",
              "  'data system',\n",
              "  'data processing',\n",
              "  'elasticsearch',\n",
              "  'natural language',\n",
              "  'data structure',\n",
              "  'database',\n",
              "  'scala',\n",
              "  'python',\n",
              "  'business',\n",
              "  'software engineering',\n",
              "  'debugging',\n",
              "  'security',\n",
              "  'algorithm',\n",
              "  'seasonality',\n",
              "  'engineering',\n",
              "  'google',\n",
              "  'ai']}"
            ]
          },
          "execution_count": 61,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "jd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cosine Similarity: 0.4839503\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "# Train Word2Vec model on a corpus of skills\n",
        "corpus = [jd[\"SKILLS\"],uniq_skills_resume] # Combine both lists into a corpus\n",
        "model = Word2Vec(corpus, min_count=1)  # Train the Word2Vec model\n",
        "\n",
        "# Calculate average vector representations for each list of skills\n",
        "vector1 = np.mean([model.wv[skill] for skill in uniq_skills_jd if skill in model.wv], axis=0)\n",
        "vector2 = np.mean([model.wv[skill] for skill in uniq_skills_resume if skill in model.wv], axis=0)\n",
        "\n",
        "# Reshape the vectors if necessary\n",
        "vector1 = vector1.reshape(1, -1)  # Reshape to a row vector\n",
        "vector2 = vector2.reshape(1, -1)  # Reshape to a row vector\n",
        "\n",
        "# Calculate cosine similarity\n",
        "similarity_score = cosine_similarity(vector1, vector2)\n",
        "\n",
        "print(\"Cosine Similarity:\", similarity_score[0][0])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.16"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
